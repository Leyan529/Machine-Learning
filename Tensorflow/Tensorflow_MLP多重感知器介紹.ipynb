{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cpu:0', '/gpu:0']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import ML\n",
    "ML.showAllVariables()\n",
    "ML.init()\n",
    "Sess = ML.limitGPUByGrowth()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w :  [[ 0.60723716 -0.72217906]\n",
      " [ 0.13419233 -0.7084074 ]\n",
      " [-2.181187    0.17033528]]\n",
      "X :  [[ 0.22946116 -0.08587574  0.1430427 ]]\n",
      "b :  [[-0.34771737  0.10832242]]\n",
      "y :  [[0.        0.0278106]]\n",
      "[-1.2319295   2.1092873   0.73041975 -0.9815725  -2.1841202 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  7.,  25.,  69., 188., 238., 217., 156.,  68.,  27.,   5.]),\n",
       " array([-2.9925189 , -2.37349792, -1.75447693, -1.13545594, -0.51643496,\n",
       "         0.10258603,  0.72160702,  1.340628  ,  1.95964899,  2.57866998,\n",
       "         3.19769096]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = tf.Variable(tf.random_normal([3,2])) #隨機產生3*2的tensor\n",
    "X = tf.Variable(tf.random_normal([1,3])) #隨機產生1*3的tensor\n",
    "\n",
    "b = tf.Variable(tf.random_normal([1,2])) #隨機產生1*2的tensor\n",
    "y = tf.nn.relu(tf.matmul(X,w)+b)\n",
    "\n",
    "ts_norm = tf.Variable(tf.random_normal([1000]))\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    (w,X,b,y) = sess.run((w,X,b,y)) #一次取得所有隨機分布變數\n",
    "    \n",
    "    print('w : ',w)\n",
    "    print('X : ',X)\n",
    "    print('b : ',b)\n",
    "    print('y : ',y)\n",
    "    \n",
    "    norm_data = ts_norm.eval()\n",
    "    print(norm_data[:5])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(norm_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w*X :  [[ 0.56190662 -0.35342253]\n",
      " [ 0.62789855 -0.43941522]\n",
      " [ 0.75170426 -0.0577053 ]]\n",
      "b :  [[1.97840557 0.50973956]]\n",
      "y :  [[2.54031219 0.15631703]\n",
      " [2.60630412 0.07032434]\n",
      " [2.73010983 0.45203427]]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.random_normal([3,2],dtype=tf.float64)) #隨機產生3*2的tensor\n",
    "X = tf.placeholder(tf.float64,[None,3]) #預備傳入一個 n*3 的矩陣\n",
    "\n",
    "b = tf.Variable(tf.random_normal([1,2],dtype=tf.float64)) #隨機產生1*2的tensor\n",
    "y = tf.nn.relu(tf.matmul(X,w)+b) #3*2 +1*2\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    X_Place = np.array([[0.4,0.2,0.4],\n",
    "                       [0.3,0.4,0.5],\n",
    "                       [0.3,-0.4,0.5]]) # 設定欲傳入3*3的矩陣\n",
    "    sess.run(init)\n",
    "    (w,X,b,y) = sess.run((w,X,b,y),feed_dict={X:X_Place}) #一次取得所有隨機分布變數\n",
    "    \n",
    "    \n",
    "    print('w*X : ',sess.run(tf.matmul(X,w)))\n",
    "    print('b : ',b)\n",
    "    print('y : ',y)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer X :  [[0.4 0.2 0.4 0.5]]\n",
      "hidden layer h :  [[0.        0.        0.5470586]]\n",
      "output layer y :  [[ 0.14205307 -0.12861785]]\n"
     ]
    }
   ],
   "source": [
    "def layer(output_dim,input_dim,inputs,activation=None): #建立兩層神經網路的函數\n",
    "    W = tf.Variable(tf.random_normal([input_dim,output_dim])) #以隨機分布的權重weight   \n",
    "    b = tf.Variable(tf.random_normal([1,output_dim])) #以隨機分布的偏差bias\n",
    "    y = tf.matmul(inputs,W) + b   # inputs = X = 輸入的二維Placeholder\n",
    "    if activation == None:\n",
    "        outputs = y\n",
    "    else:\n",
    "        outputs = activation(y) # activation:傳入的激活函數\n",
    "    return outputs\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,4]) #預備傳入一個 n*4 的矩陣\n",
    "h = layer(input_dim=4,output_dim=3,inputs=X,activation=tf.nn.relu)\n",
    "y = layer(input_dim=3,output_dim=2,inputs=h)\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = [[0.4,0.2,0.4,0.5]] # 設定欲傳入1*4的張量\n",
    "    (layer_X,layer_h,layer_y) = sess.run((X,h,y),feed_dict={X:X_array})\n",
    "    print('input layer X : ',layer_X)\n",
    "    print('hidden layer h : ',layer_h)\n",
    "    print('output layer y : ',layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer X :  [[0.4 0.2 0.4 0.5]] \n",
      "\n",
      "hidden layer h :  [[1.1533617 0.        0.       ]] \n",
      "W1 :  [[ 0.5922188   0.25474983  0.10478781]\n",
      " [ 1.2748152  -1.7732375   0.19224627]\n",
      " [ 0.64803505 -0.84489757  1.2307391 ]\n",
      " [ 1.6979189   0.9754334  -1.7246691 ]] \n",
      "b1 :  [[-0.44666228 -0.5114812  -0.36872932]] \n",
      "\n",
      "output layer y :  [[ 2.759932  -1.9069697]] \n",
      "W2 :  [[ 1.1513695  -0.56502783]\n",
      " [ 0.20108788  0.7066875 ]\n",
      " [ 1.2040243  -1.0962665 ]] \n",
      "b2 :  [[ 1.4319868 -1.2552882]]\n"
     ]
    }
   ],
   "source": [
    "def layer(output_dim,input_dim,inputs,activation=None): #建立兩層神經網路的函數\n",
    "    W = tf.Variable(tf.random_normal([input_dim,output_dim])) #以隨機分布的權重weight   \n",
    "    b = tf.Variable(tf.random_normal([1,output_dim])) #以隨機分布的偏差bias\n",
    "    y = tf.matmul(inputs,W) + b   # inputs = X = 輸入的二維Placeholder\n",
    "    if activation == None:\n",
    "        outputs = y\n",
    "    else:\n",
    "        outputs = activation(y) # activation:傳入的激活函數\n",
    "    return outputs,W,b\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,4]) #預備傳入一個 n*4 的矩陣\n",
    "h,W1,b1 = layer(input_dim=4,output_dim=3,inputs=X,activation=tf.nn.relu)\n",
    "y,W2,b2 = layer(input_dim=3,output_dim=2,inputs=h)\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = [[0.4,0.2,0.4,0.5]] # 設定欲傳入1*4的張量\n",
    "    (layer_X,layer_h,layer_y,W1,W2,b1,b2) = sess.run((X,h,y,W1,W2,b1,b2),feed_dict={X:X_array})\n",
    "    print('input layer X : ',layer_X ,\"\\n\")\n",
    "    print('hidden layer h : ',layer_h,\"\\nW1 : \", W1,\"\\nb1 : \",b1,\"\\n\")\n",
    "    print('output layer y : ',layer_y,\"\\nW2 : \", W2,\"\\nb2 : \",b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
